{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender Identification Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "#### Given the name, can we identify the gender of the person?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the timer\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the initial Train dataset\n",
    "dt = pd.read_csv(\"../../Njambanene/Tasks/Name_Identification/Feb  Members Spend Analysis  - Active 1 Members.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Sample the dataset\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename column\n",
    "dt = dt.rename(columns={'Member Name': 'Name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check data types and attributes\n",
    "print(dt.columns)\n",
    "\n",
    "print(dt.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_one_word_names(name):\n",
    "  \"\"\"Counts the number of names with one word in a list of names.\n",
    "\n",
    "  Args:\n",
    "    names: A list of names.\n",
    "\n",
    "  Returns:\n",
    "    The number of names with one word.\n",
    "  \"\"\"\n",
    "\n",
    "  count = 0\n",
    "  for name in name:\n",
    "    if len(name.split()) == 1:\n",
    "      count += 1\n",
    "  return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## proportion of one-word names\n",
    "one_word_names = round(count_one_word_names(dt['Name'])/len(dt)*100,2)\n",
    "\n",
    "print(f\"The proportion of one-word names is: {one_word_names}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = dt['Name'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace col values\n",
    "# dt['Gender'] = dt['Gender'].replace({0:\"M\",1:\"F\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## shape of data\n",
    "print(dt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for Cleaning Names\n",
    "def clean_name(value):\n",
    "    # Convert float values to string\n",
    "    if isinstance(value, float):\n",
    "        value = str(value)\n",
    "\n",
    "    # Truncate the name to the first three words\n",
    "    words = value.split()\n",
    "    truncated_words = words[:3]\n",
    "    truncated_name = ' '.join(truncated_words)\n",
    "\n",
    "    # Remove extraneous white spaces using regular expression substitution\n",
    "    dropped_whitespaces = re.sub(r'\\s+', ' ', truncated_name)\n",
    "\n",
    "    # Drop non-name words and remove characters after hyphen, underscore, or brackets\n",
    "    pattern = r\"\\b(?:[^A-Za-z\\s]|(?!^)\\d)\\b|[-_()\\[\\]]\"\n",
    "    names_only = re.sub(pattern, '', dropped_whitespaces)\n",
    "\n",
    "    # Remove the pattern and everything after it\n",
    "    pattern = r\"\\b(?:DO NOT|DONT|SAYS|REQUEST|CUSTOMER|LOCK|NOT|REQUESTED|ACCOUNT|TRANSFER|CUSTOMERS|DONOT|REPORTED|LOST|STOLEN|COOKER|CANISTER|KINDLY|GIVE)\\b.*\"\n",
    "    drop_nonnames = re.sub(pattern, '', names_only)\n",
    "\n",
    "    # Remove special characters (excluding spaces) from the name\n",
    "    pattern = r'[^A-Za-z\\s]'\n",
    "    cleaned_name = re.sub(pattern, '', drop_nonnames)\n",
    "\n",
    "    return cleaned_name.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the clean function to the 'Name' column\n",
    "dt['Cleaned Name'] = dt['Name'].apply(clean_name)#apply(convert_float_and_remove_numbers).apply(truncate_drop_and_clean)\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## unique names \n",
    "print(len(dt['Cleaned Name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot for male and female names in the data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the countplot\n",
    "ax = sns.countplot(x='Gender', data=dt)\n",
    "\n",
    "# Calculate the proportions for each category\n",
    "total = len(dt)\n",
    "counts = dt['Gender'].value_counts()\n",
    "proportions = counts / total\n",
    "\n",
    "# Sort the counts and proportions in descending order\n",
    "sorted_counts = counts.sort_values(ascending=False)\n",
    "sorted_proportions = proportions.loc[sorted_counts.index]\n",
    "\n",
    "\n",
    "# Add the proportions as annotations\n",
    "for i, p in enumerate(ax.patches):\n",
    "    x = p.get_x() + p.get_width() / 2\n",
    "    y = p.get_height()\n",
    "    label = f\"{sorted_proportions[i]:.2%}\"\n",
    "    ax.annotate(label, (x, y), ha='center', va='bottom')\n",
    "\n",
    "sns.countplot(x='Gender', data=dt)\n",
    "plt.title('No of male and female names in the dataset')\n",
    "plt.xticks([0,1],('Female','Male'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## analyze starting letters of names\n",
    "alphabets= ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P',\n",
    "\n",
    "            'Q','R','S','T','U','V','W','X','Y','Z']\n",
    "\n",
    "startletter_count = {}\n",
    "\n",
    "for i in alphabets:\n",
    "\n",
    "    startletter_count[i] = len(dt[dt['Name'].str.startswith(i)])\n",
    "\n",
    "print(startletter_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize starting letters\n",
    "plt.figure(figsize = (16,8))\n",
    "\n",
    "plt.bar(startletter_count.keys(),startletter_count.values())\n",
    "\n",
    "plt.xlabel('Starting alphabet')\n",
    "\n",
    "plt.ylabel('No. of names')\n",
    "\n",
    "plt.title('Number of names starting with each letter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check most common starting alphabets\n",
    "print('The 5 most common starting letters are : ', *sorted (startletter_count.items(),key=lambda item: item[1])[-5:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## analyze ending letters of names\n",
    "small_alphabets = ['a','b','c','d','e','f','g','h',\n",
    "\n",
    "                   'i','j','k','l','m','n','o','p','q','r','s','t','u','v','x','y','z']\n",
    "\n",
    "endletter_count ={}\n",
    "\n",
    "for i in small_alphabets:\n",
    "    endletter_count[i] = len(dt[dt['Name'].str.endswith(i)])\n",
    "\n",
    "print(endletter_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,8))\n",
    "\n",
    "plt.bar(endletter_count.keys(),endletter_count.values())\n",
    "\n",
    "plt.xlabel('Ending alphabet')\n",
    "\n",
    "plt.ylabel('No. of names')\n",
    "\n",
    "plt.title('Number of names ending with each letter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## most common name ending letters\n",
    "print(\"The 5 most name ending letters are : \",*sorted(endletter_count.items(),\n",
    "                                                      key=lambda item: item[1])[-5:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a word cloud\n",
    "\n",
    "text =  \" \".join(i for i in dt.Name)\n",
    "\n",
    "word_cloud = WordCloud(\n",
    "\n",
    "        width=3000,\n",
    "\n",
    "        height=2000,\n",
    "\n",
    "        random_state=1,\n",
    "\n",
    "        background_color=\"white\",\n",
    "\n",
    "        colormap=\"BuPu\",\n",
    "\n",
    "        collocations=False,\n",
    "        stopwords= STOPWORDS,\n",
    "\n",
    "        ).generate(text)\n",
    "\n",
    "plt.imshow(word_cloud)\n",
    "\n",
    "plt.axis(\"off\")    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build model\n",
    "X = list(dt['Cleaned Name'])\n",
    "Y = list(dt['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## encode the labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## count vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(analyzer = 'char')\n",
    "X = cv.fit_transform(X).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.33, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_model = LogisticRegression()\n",
    "LR_model.fit(x_train, y_train)\n",
    "LR_y_pred = LR_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(x_train, y_train)\n",
    "NB_y_pred = NB_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create an instance of the KNN classifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the KNN model\n",
    "knn_model.fit(x_train, y_train)\n",
    "knn_y_pred = knn_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preview prediction output\n",
    "df_predictions2 = pd.DataFrame({'Name': dt.loc[range(len(x_test)),'Name'], 'Predicted_Gender': encoder.inverse_transform(knn_y_pred)})\n",
    "df_predictions2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Define the seed\n",
    "seed = 42\n",
    "\n",
    "XGB_model = XGBClassifier(random_state= seed) #use_label_encoder = False\n",
    "XGB_model.fit(x_train,y_train)\n",
    "XGB_y_pred = XGB_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preview prediction output\n",
    "\n",
    "XGB_y_pred = XGB_y_pred.tolist()\n",
    "df_predictions = pd.DataFrame({'Cleaned Name': dt.loc[range(len(x_test)), 'Cleaned Name'], 'Predicted_Gender': encoder.inverse_transform(XGB_y_pred)})\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparison of performance\n",
    "### function for confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def cmatrix(model):\n",
    "    y_pred = model.predict(x_test)\n",
    "    cmatrix = confusion_matrix(y_test,y_pred)\n",
    "    print(cmatrix)\n",
    "    sns.heatmap(cmatrix,fmt = 'd',cmap='BuPu', annot=True)\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.title('Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# for logistic regression\n",
    "accuracy = metrics.accuracy_score(LR_y_pred,y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "\n",
    "print(metrics.classification_report(y_test,LR_y_pred))\n",
    "print(cmatrix(LR_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for naive bayes\n",
    "\n",
    "accuracy = metrics.accuracy_score(NB_y_pred,y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "\n",
    "print(metrics.classification_report(y_test, NB_y_pred))\n",
    "\n",
    "print(cmatrix(NB_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for knn\n",
    "accuracy = metrics.accuracy_score(knn_y_pred,y_test)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "\n",
    "print(metrics.classification_report(y_test,knn_y_pred))\n",
    "\n",
    "print(cmatrix(knn_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for XGBoost\n",
    "print(metrics.accuracy_score(XGB_y_pred,y_test))\n",
    "\n",
    "accuracy = metrics.accuracy_score(XGB_y_pred,y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "\n",
    "print(metrics.classification_report(y_test, XGB_y_pred))\n",
    "\n",
    "print(cmatrix(XGB_model))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosen Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Define the seed\n",
    "seed = 42\n",
    "\n",
    "XGB_model = XGBClassifier(random_state = seed) #use_label_encoder = False\n",
    "XGB_model.fit(x_train,y_train)\n",
    "\n",
    "# Save the model and the seed\n",
    "model_filename = \"name_classification_xgb.pkl\"\n",
    "model_data = {\n",
    "    \"model\": XGB_model,\n",
    "    \"seed\": seed\n",
    "}\n",
    "\n",
    "with open(model_filename, \"wb\") as file:\n",
    "    pickle.dump(model_data, file)\n",
    "\n",
    "\n",
    "XGB_y_pred = XGB_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preview prediction output\n",
    "\n",
    "XGB_y_pred = XGB_y_pred.tolist()\n",
    "dt_predictions = pd.DataFrame({'Cleaned Name': dt.loc[range(len(x_test)), 'Name'], 'Predicted_Gender': encoder.inverse_transform(XGB_y_pred)})\n",
    "dt_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run predictions on cust_prof_gend data --validation of data w Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# pydomo_client_id = os.getenv('PYDOMO_CLIENTID')\n",
    "# pydomo_secret = os.getenv('PYDOMO_SECRET')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create domo python connection\n",
    "from pydomo import Domo\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "\n",
    "env_values = dotenv_values('.env')\n",
    "\n",
    "domo = Domo(env_values['PYDOMO_CLIENTID'], env_values['PYDOMO_SECRET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a data set from Domo\n",
    "cust_prof_gender = domo.ds_get('9e6aecb0-9669-4787-894d-43c496b4c928')\n",
    "cust_prof_gender.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop unnecessary columns\n",
    "cust_prof_gender = cust_prof_gender.drop(['num_canisters','is_club_customer'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map values from 1 to \"female\" and 2 to \"male\" in the 'Gender' column\n",
    "cust_prof_gender['gender'] = cust_prof_gender['gender'].map({1: 'Female', 2: 'Male'})\n",
    "cust_prof_gender['gender'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot for male and female names in the loaded data\n",
    "\n",
    "# Create the countplot\n",
    "ax = sns.countplot(x='gender', data=cust_prof_gender)\n",
    "\n",
    "# Calculate the proportions for each category\n",
    "total = len(cust_prof_gender)\n",
    "counts = cust_prof_gender['gender'].value_counts()\n",
    "proportions = counts / total\n",
    "\n",
    "# Add the proportions as annotations\n",
    "for i, p in enumerate(ax.patches):\n",
    "    x = p.get_x() + p.get_width() / 2\n",
    "    y = p.get_height()\n",
    "    label = f\"{proportions[i]:.2%}\"\n",
    "    ax.annotate(label, (x, y), ha='center', va='bottom')\n",
    "\n",
    "# Set the title and x-axis tick labels\n",
    "plt.title('No of male and female names in the dataset')\n",
    "plt.xticks(ticks=[0, 1], labels=['Female', 'Male'])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  ## proportion of one-word names\n",
    "one_word_names2 = round(count_one_word_names(cust_prof_gender['name'])/len(cust_prof_gender)*100,2)\n",
    "\n",
    "print(f\"The proportion of one-word-names is: {one_word_names2}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## update dataset to predict\n",
    "# df = pd.read_csv(\"../../Njambanene/Tasks/Name_Identification/Fuel Customers_test.csv\")\n",
    "df = cust_prof_gender\n",
    "## rename col\n",
    "df = df.rename(columns= {'name': 'Name','gender':'Gender'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check shape\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the clean function to the 'Name' column\n",
    "df['Cleaned Name'] = df['Name'].apply(clean_name)#apply(convert_float_and_remove_numbers).apply(truncate_drop_and_clean)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = add_name_length_column(df['Cleaned Name']).sort_values(by ='Name Length' ,ascending=False)\n",
    "# df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing transforms\n",
    "df_test = list(df['Cleaned Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## vectorization\n",
    "df_test = cv.fit_transform(df_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## truncate to train data's number of attributes\n",
    "# num_attributes = X.shape[1]\n",
    "\n",
    "# truncated_array = cv.fit_transform(df_test).toarray()[:, :num_attributes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check shape of training vs test data\n",
    "# df_test = truncated_array\n",
    "print(\"Shape of df_test:\", df_test.shape)\n",
    "# print(\"Shape of truncated_array:\", truncated_array.shape)\n",
    "\n",
    "print(\"Shape of df_train:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load and run saved model\n",
    "### Run the model on new data\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the saved model and seed\n",
    "model_filename = \"name_classification_xgb.pkl\"\n",
    "\n",
    "with open(model_filename, \"rb\") as file:\n",
    "    model_data = pickle.load(file)\n",
    "\n",
    "XGB_model = model_data[\"model\"]\n",
    "seed = model_data[\"seed\"]\n",
    "\n",
    "\n",
    "predictions = XGB_model.predict(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preview prediction output\n",
    "\n",
    "predictions = predictions.tolist()\n",
    "cust_prof_gender_predictions = pd.DataFrame({'customer_id': df['customer_id'],'Cleaned Name': df.loc[range(len(df_test)), 'Cleaned Name'], 'Predicted_Gender': encoder.inverse_transform(predictions)})\n",
    "cust_prof_gender_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_prof_gender_predictions.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## join prediction with original dataset for validations\n",
    "df2 = df.merge(cust_prof_gender_predictions,left_index=True,right_index=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Predictions with Gender Data Already Captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter accurate matches\n",
    "matched_mask = df2['Gender'] == df2['Predicted_Gender']\n",
    "matched_rows = df2[matched_mask]\n",
    "\n",
    "matched_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## proportion of matches to customer data with Gender\n",
    "match_percentage = round(len(matched_rows)/len(cust_prof_gender)*100,2)\n",
    "\n",
    "print(f\"The match percentage is: {match_percentage}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_rows = matched_rows.drop(columns=['Name','Gender','Cleaned Name_x','customer_id_x'], axis=1)\n",
    "matched_rows = matched_rows.rename(columns={'Cleaned Name_y':'Cleaned Name','customer_id_y':'customer_id' })#, 'Predicted_Gender':'Gender'\n",
    "matched_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## duplicate data for storage\n",
    "df_predictions = matched_rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Append Predicted-Matched data with former Test data\n",
    "# Concatenate datasets based on matching columns\n",
    "merged_train_dt = pd.concat([dt_predictions, df_predictions], axis=0, ignore_index=True)\n",
    "merged_train_dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  ## proportion of one-word names\n",
    "one_word_names2a = round(count_one_word_names(merged_train_dt['Cleaned Name'])/len(merged_train_dt)*100,2)\n",
    "\n",
    "print(f\"The proportion of one-word-names is: {one_word_names2a}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_dt['Predicted_Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(merged_train_dt)\n",
    "counts = merged_train_dt['Predicted_Gender'].value_counts()\n",
    "proportions = counts / total\n",
    "proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot for male and female names in the merged training data\n",
    "\n",
    "# Calculate the counts and proportions\n",
    "counts = merged_train_dt['Predicted_Gender'].value_counts()\n",
    "proportions = counts / len(merged_train_dt)\n",
    "\n",
    "# Sort the counts and proportions in descending order\n",
    "sorted_counts = counts.sort_values(ascending=False)\n",
    "sorted_proportions = proportions.loc[sorted_counts.index]\n",
    "\n",
    "# Create the countplot with sorted data\n",
    "ax = sns.countplot(x='Predicted_Gender', data=merged_train_dt, order=sorted_counts.index)\n",
    "\n",
    "# Add the proportions as annotations\n",
    "for i, p in enumerate(ax.patches):\n",
    "    x = p.get_x() + p.get_width() / 2\n",
    "    y = p.get_height()\n",
    "    label = f\"{sorted_proportions[i]:.2%}\"\n",
    "    ax.annotate(label, (x, y), ha='center', va='bottom')\n",
    "\n",
    "# Set the title and x-axis tick labels\n",
    "plt.title('No of male and female names in the dataset')\n",
    "plt.xticks(ticks=[0, 1], labels=['Female', 'Male'])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train another model on merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run clean function on names\n",
    "merged_train_dt['Cleaned Name'] = merged_train_dt['Cleaned Name'].apply(clean_name)#apply(convert_float_and_remove_numbers).apply(truncate_drop_and_clean)\n",
    "merged_train_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build model\n",
    "X = list(merged_train_dt['Cleaned Name'])\n",
    "Y = list(merged_train_dt['Predicted_Gender'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## encode the labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## count vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(analyzer = 'char')\n",
    "X = cv.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.33, random_state= 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train another model on merged data\n",
    "# Define the seed\n",
    "seed = 43\n",
    "\n",
    "XGB_model2 = XGBClassifier(random_state = seed) #use_label_encoder = False\n",
    "XGB_model2.fit(x_train,y_train)\n",
    "\n",
    "# Save the model and the seed\n",
    "model_filename = \"name_classification_xgb2.pkl\"\n",
    "model_data = {\n",
    "    \"model\": XGB_model2,\n",
    "    \"seed\": seed\n",
    "}\n",
    "\n",
    "with open(model_filename, \"wb\") as file:\n",
    "    pickle.dump(model_data, file)\n",
    "\n",
    "\n",
    "XGB_y_pred2 = XGB_model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for XGBoost\n",
    "# print(metrics.accuracy_score(XGB_y_pred2,y_test))\n",
    "\n",
    "accuracy = metrics.accuracy_score(XGB_y_pred2,y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "\n",
    "print(metrics.classification_report(y_test, XGB_y_pred2))\n",
    "\n",
    "print(cmatrix(XGB_model2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Prediction on Entire Customer Profile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download  entire cust dataset from Domo\n",
    "cust_prof = domo.ds_get('6ab44284-0840-4af4-a316-09e993e0065a')\n",
    "cust_prof.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check shape\n",
    "cust_prof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map values from 1 to \"female\" and 2 to \"male\" in the 'Gender' column\n",
    "cust_prof['gender'] = cust_prof['gender'].map({1: 'Female', 2: 'Male'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select key cols\n",
    "\n",
    "cols_of_interest = ['customer_id','name']#,'gender'\n",
    "cust_prof = cust_prof[cols_of_interest]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## filter data already in train data\n",
    "cust_prof = cust_prof.reset_index(drop=True)\n",
    "matched_rows = matched_rows.reset_index(drop=True)\n",
    "\n",
    "df4 = cust_prof.drop(cust_prof[cust_prof['customer_id'].isin(matched_rows['customer_id'])].index)\n",
    "## check shape after\n",
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop nas\n",
    "df4 = df4.dropna(how = 'all')\n",
    "## rename cols\n",
    "df4 = df4.rename(columns= {'name': 'Name'})#,'gender':'Gender'\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  ## proportion of one-word names\n",
    "one_word_names3 = round(count_one_word_names(df4['Name'])/len(df4)*100,2)\n",
    "\n",
    "print(f\"The proportion of one-word-names is: {one_word_names3}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing Final Prediction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_name_length_column(names):\n",
    "  \"\"\"Adds a column of the number of characters in each name to a DataFrame.\n",
    "\n",
    "  Args:\n",
    "    names: A list of names.\n",
    "\n",
    "  Returns:\n",
    "    A DataFrame with a column of the number of characters in each name.\n",
    "  \"\"\"\n",
    "  name_lengths = []\n",
    "  for name in names:\n",
    "    name_length = len(name)\n",
    "    name_lengths.append(name_length)\n",
    "\n",
    "  df = pd.DataFrame({'Name': names})\n",
    "  df['Name Length'] = name_lengths\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the name with most characters\n",
    "\n",
    "# df4 = add_name_length_column(df4['Name']).sort_values(by ='Name Length' ,ascending=False)\n",
    "# df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply the truncate_names function to the 'Name' column\n",
    "df4['Cleaned Name'] = df4['Name'].apply(clean_name)\n",
    "df4.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing transforms\n",
    "dm_test = list(df4['Cleaned Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with empty strings\n",
    "# df_test2 = ['' if pd.isna(value) else value for value in df_test2]\n",
    "\n",
    "## truncate to train data's number of attributes\n",
    "# num_attributes = X.shape[1]\n",
    "\n",
    "# truncated_array = cv.fit_transform(df_test2).toarray()[:, :num_attributes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## vectorization\n",
    "\n",
    "dm_test = cv.fit_transform(dm_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check shape of training vs test data\n",
    "# df_test2 = truncated_array\n",
    "print(\"Shape of dm_test:\", dm_test.shape)\n",
    "# print(\"Shape of truncated_array:\", truncated_array.shape)\n",
    "\n",
    "print(\"Shape of df_train:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## load and run saved model\n",
    "### Run the model on new data\n",
    "\n",
    "\n",
    "# Load the saved model and seed\n",
    "model_filename = \"name_classification_xgb2.pkl\"\n",
    "\n",
    "with open(model_filename, \"rb\") as file:\n",
    "    model_data = pickle.load(file)\n",
    "\n",
    "XGB_model2 = model_data[\"model\"]\n",
    "seed = model_data[\"seed\"]\n",
    "\n",
    "\n",
    "predictions2 = XGB_model2.predict(dm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = predictions2.tolist()\n",
    "# customer_f_dt = customer_f_dt.reset_index(drop=True)\n",
    "\n",
    "cust_profile_predictions = pd.DataFrame({'customer_id': df4['customer_id'],'Cleaned Name': df4['Cleaned Name'],'Predicted_Gender': encoder.inverse_transform(predictions2)\n",
    "})\n",
    "cust_profile_predictions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_profile_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append Predictions to Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_prof_gender_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## append matched rows with dt\n",
    "all_cust_prof_data = pd.concat([cust_prof_gender_predictions,cust_profile_predictions],axis=0, ignore_index=True)\n",
    "all_cust_prof_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cust_prof_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop Duplicated records\n",
    "all_cust_prof_data.drop_duplicates(subset='customer_id', inplace=True)\n",
    "all_cust_prof_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Gender Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  ## proportion of one-word names\n",
    "one_word_names4 = round(count_one_word_names(all_cust_prof_data['Cleaned Name'])/len(all_cust_prof_data)*100,2)\n",
    "\n",
    "print(f\"The proportion of one-word-names is: {one_word_names4}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "all_cust_prof_data['Predicted_Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot for male and female names in the data\n",
    "\n",
    "# Create the countplot\n",
    "ax = sns.countplot(x='Predicted_Gender', data=all_cust_prof_data)\n",
    "\n",
    "# Calculate the proportions for each category\n",
    "total = len(all_cust_prof_data)\n",
    "counts = all_cust_prof_data['Predicted_Gender'].value_counts()\n",
    "proportions = counts / total\n",
    "\n",
    "# Sort the counts and proportions in descending order\n",
    "sorted_counts = counts.sort_values(ascending=False)\n",
    "sorted_proportions = proportions.loc[sorted_counts.index]\n",
    "\n",
    "\n",
    "# Add the proportions as annotations\n",
    "for i, p in enumerate(ax.patches):\n",
    "    x = p.get_x() + p.get_width() / 2\n",
    "    y = p.get_height()\n",
    "    label = f\"{sorted_proportions[i]:.2%}\"\n",
    "    ax.annotate(label, (x, y), ha='center', va='bottom')\n",
    "\n",
    "# Set the title and x-axis tick labels\n",
    "plt.title('No of male and female names in the dataset')\n",
    "plt.xticks(ticks=[0, 1], labels=['Female', 'Male'])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output predicted genders\n",
    "all_cust_prof_data.to_csv('../../Njambanene/Tasks/Name_Identification/KOKO Users -Name based Gender Classification.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data set in Domo with the result, the return value is the data set id of the new data set.\n",
    "# all_cust_prof_data = domo.ds_create(all_cust_prof_data,'Customer Gender Dataset','Python')\n",
    "## previously created dataset\n",
    "all_cust_prof_data_prev = domo.ds_get('378b0d4e-1f77-4e7d-b4f0-cb62d974e550')\n",
    "all_cust_prof_data_prev.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## update the previously created dataset\n",
    "all_cust_prof_data = domo.ds_create(all_cust_prof_data,'Customer Gender Dataset_Update','Python')\n",
    "all_cust_prof_data_update = domo.ds_update(all_cust_prof_data,all_cust_prof_data_prev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cust_prof_data = pd.read_csv('../../Njambanene/Tasks/Name_Identification/KOKO Users -Name based Gender Classification.csv')\n",
    "## Check for additional rows\n",
    "current_rows = all_cust_prof_data.shape[0]\n",
    "previous_rows = all_cust_prof_data_prev.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the number of rows\n",
    "if current_rows > previous_rows:\n",
    "    additional_rows = current_rows - previous_rows\n",
    "    print(f\"There are {additional_rows} additional rows in the current dataset.\")\n",
    "else:\n",
    "    print(\"No additional rows have been added to the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print the elapsed time\n",
    "print(\"Elapsed time:\", elapsed_time, \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Note:\n",
    "Although we were able to predict the gender of majority of the names accurately with ~96% accuracy, below are are some disclaimers that influenced the accuracy of the model:\n",
    "1. One-Word Names: There was a significant number of one word names both in the training set (~63%) and the test data (~50%) that reduces the ability to predict gender accurately.\n",
    "2. Data Bias and Representation: There is a potential bias in the training data used to develop the model as female customers was ~60%  of the data. As such the model's predictions may reflect the biases present in the data, such as underrepresentation or overrepresentation.\n",
    "3. Name complexity: Due to the limitation of the model processing only three names for a customer (at most), there is a possibility of incorrect predictions if two of the names could potentially belong to both male and female genders individually.\n",
    "4. Third Gender Representation: It's important to note that the model does not consider gender-fluid or non-binary individuals. Instead, it primarily categorizes names into male or female genders and predicts the gender that is most commonly associated with a given name. This means that the model may not accurately represent or predict the gender for individuals who identify as gender-fluid or non-binary.\n",
    "5. Name Ambiguity and Variability: Some names had numbers, names of places e.g. shops, special characters as well aliases that were dropped during name clean up. More-over some names can be gender-neutral or may have varying associations across different cultures, hence the model may be inaccurate in such instances. Names that are used for both males and females can introduce ambiguity in the model's predictions.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a function based on ner (pre-trained named entity recognition (NER) model) for name-checking \n",
    "# import spacy\n",
    "\n",
    "# def is_name(word):\n",
    "#     # Load the pre-trained English NER model from spaCy\n",
    "#     nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "#     # Process the word with the NER model\n",
    "#     doc = nlp(word)\n",
    "    \n",
    "#     # Check if any entity in the word is classified as a person (PERSON)\n",
    "#     return any(ent.label_ == 'PERSON' for ent in doc.ents)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
